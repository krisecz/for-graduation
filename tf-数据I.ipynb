{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "训练开始...\n",
      "第  0次训练的损失值：0.152008\n",
      "第100次训练的损失值：0.004220\n",
      "第200次训练的损失值：0.003853\n",
      "第300次训练的损失值：0.003681\n",
      "第400次训练的损失值：0.003582\n",
      "第500次训练的损失值：0.003520\n",
      "第600次训练的损失值：0.003440\n",
      "第700次训练的损失值：0.003361\n",
      "第800次训练的损失值：0.003304\n",
      "第900次训练的损失值：0.003265\n",
      "第1000次训练的损失值：0.003236\n",
      "第1100次训练的损失值：0.003215\n",
      "第1200次训练的损失值：0.003062\n",
      "第1300次训练的损失值：0.002786\n",
      "第1400次训练的损失值：0.002616\n",
      "第1500次训练的损失值：0.002486\n",
      "第1600次训练的损失值：0.002375\n",
      "第1700次训练的损失值：0.002280\n",
      "第1800次训练的损失值：0.002198\n",
      "第1900次训练的损失值：0.002127\n",
      "第2000次训练的损失值：0.002069\n",
      "第2100次训练的损失值：0.002023\n",
      "第2200次训练的损失值：0.001981\n",
      "第2300次训练的损失值：0.001942\n",
      "第2400次训练的损失值：0.001906\n",
      "第2500次训练的损失值：0.001872\n",
      "第2600次训练的损失值：0.001839\n",
      "第2700次训练的损失值：0.001809\n",
      "第2800次训练的损失值：0.001779\n",
      "第2900次训练的损失值：0.001752\n",
      "第3000次训练的损失值：0.001725\n",
      "第3100次训练的损失值：0.001700\n",
      "第3200次训练的损失值：0.001675\n",
      "第3300次训练的损失值：0.001652\n",
      "第3400次训练的损失值：0.001629\n",
      "第3500次训练的损失值：0.001606\n",
      "第3600次训练的损失值：0.001583\n",
      "第3700次训练的损失值：0.001560\n",
      "第3800次训练的损失值：0.001539\n",
      "第3900次训练的损失值：0.001517\n",
      "第4000次训练的损失值：0.001497\n",
      "第4100次训练的损失值：0.001476\n",
      "第4200次训练的损失值：0.001457\n",
      "第4300次训练的损失值：0.001437\n",
      "第4400次训练的损失值：0.001418\n",
      "第4500次训练的损失值：0.001399\n",
      "第4600次训练的损失值：0.001381\n",
      "第4700次训练的损失值：0.001363\n",
      "第4800次训练的损失值：0.001345\n",
      "第4900次训练的损失值：0.001327\n",
      "训练集均方误差： 0.0013101\n",
      "tensor_name:  layer1/biases/b\n",
      "tensor_name:  layer1/weights/W\n",
      "tensor_name:  layer2/biases/b\n",
      "tensor_name:  layer2/weights/W\n",
      "INFO:tensorflow:Restoring parameters from test-ckpt/model\n",
      "测试集均方误差： 0.00290034\n"
     ]
    }
   ],
   "source": [
    "# coding:utf8\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "%matplotlib auto\n",
    "\n",
    "ops.reset_default_graph() \n",
    "\n",
    "def add_layer(inputs,in_size,out_size,n_layer,activation_function=None):\n",
    "    layer_name = 'layer%s'% n_layer\n",
    "    with tf.name_scope(layer_name):\n",
    "        with tf.name_scope('weights'):\n",
    "            Weights = tf.Variable(tf.random_normal([in_size,out_size]),name='W') # 就是建造一个数组，[行,列]\n",
    "            tf.summary.histogram(layer_name+'/weights',Weights) # 让weights\n",
    "        with tf.name_scope('biases'):\n",
    "            biases = tf.Variable(tf.zeros([1,out_size]) + 0.1,name='b')\n",
    "            tf.summary.histogram(layer_name+'/biases',biases)\n",
    "        with tf.name_scope('Wx'):\n",
    "            Wx_plus_b=tf.matmul(inputs,Weights) + biases # 计算\n",
    "        if activation_function is None: # 如果不指定激励函数\n",
    "            outputs = Wx_plus_b\n",
    "        else:\n",
    "            outputs = activation_function(Wx_plus_b) # 如果指定了激励函数\n",
    "        tf.summary.histogram(layer_name+'/outputs',outputs)\n",
    "        return outputs\n",
    "\n",
    "#读取数据\n",
    "npg= pd.read_csv('nanoindentation.csv',header=0)\n",
    "npg_df = npg.values\n",
    "npg_arr= np.array(npg_df)\n",
    "scarler= preprocessing.MinMaxScaler()\n",
    "npg_arr_minmax=scarler.fit_transform(npg_arr)\n",
    "x= npg_arr_minmax[:,:2]\n",
    "y= npg_arr_minmax[:,2:3]\n",
    "\n",
    "#交叉验证\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=2)\n",
    "costs = [] \n",
    "\n",
    "with tf.name_scope('inputs'):\n",
    "    xs = tf.placeholder(tf.float32,[None,2],name='x_input')\n",
    "    ys = tf.placeholder(tf.float32,[None,1],name='y_input')\n",
    "\n",
    "l1 = add_layer(xs,2,8,n_layer=1,activation_function=tf.nn.relu) # 输入数据是xs,１个输入，8个输出，层数是１，激励函数是relu\n",
    "predition = add_layer(l1,8,1,n_layer=2,activation_function=None) # 输入数据是l1的输出, 8个输入，１个输出，层数是２，无激励函数\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "    loss = tf.losses.mean_squared_error(ys,predition)\n",
    "    tf.summary.scalar('loss',loss) # 记录loss的，可以用tensorboard查看\n",
    "\n",
    "learning_rate=0.2\n",
    "\n",
    "with tf.name_scope('optimizer'):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "    \n",
    "saver = tf.train.Saver()\n",
    " \n",
    "#初始化权重和阈值\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "summary_op = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter(\"npg1/\",sess.graph)\n",
    "sess.run(init)\n",
    "\n",
    "fig = plt.figure() # 用这个画图\n",
    "ax = fig.add_subplot(1,1,1) # 图片编号\n",
    "num=np.arange(1,20).reshape(y_train.shape)\n",
    "ax.scatter(num,y_train) # 点的编号\n",
    "plt.xticks(num)\n",
    "plt.ion() # 不用停顿\n",
    "plt.show()\n",
    "\n",
    "# 训练部分\n",
    "print(\"训练开始...\")\n",
    "for epoch in range(5000):\n",
    "    #为了将loss画图用了一种莫名奇妙的方法\n",
    "    epoch_cost = 0\n",
    "    _,cost = sess.run([optimizer,loss],feed_dict={xs:x_train,ys:y_train})\n",
    "    epoch_cost=cost\n",
    "    if epoch%100 == 0:\n",
    "        print(\"第%3d次训练的损失值：%lf\"% (epoch,epoch_cost))\n",
    "        result = sess.run(summary_op,feed_dict={xs:x_train,ys:y_train})\n",
    "        writer.add_summary(result,epoch) # 每i步输出一个结果\n",
    "        try:\n",
    "            ax.lines.remove(lines[0]) # 去除上次的线\n",
    "        except Exception:\n",
    "            pass\n",
    "        \n",
    "        predition_value = sess.run(predition,feed_dict={xs:x_train}) # 预测值\n",
    "        lines = ax.plot(num,predition_value,'r-',lw=2) # 用红色，宽度为５的曲线的形式画出来预测曲线\n",
    "        plt.pause(0.1)\n",
    "        #不知道要不要加\n",
    "        plt.show()\n",
    "\n",
    "    if epoch%5 == 0:\n",
    "        costs.append(epoch_cost)\n",
    "        \n",
    "saver.save(sess, 'test-ckpt/model')\n",
    "\n",
    "print(\"训练集均方误差：\",sess.run(loss, feed_dict={xs: x_train, ys: y_train}))\n",
    "\n",
    "\n",
    "# plot the loss\n",
    "#plt.plot(np.squeeze(costs))\n",
    "#plt.ylabel('costs')\n",
    "#plt.xlabel('epochs (per 5)')\n",
    "#plt.title(\"Learning rate = \" + str(learning_rate))\n",
    "#plt.show()\n",
    "\n",
    "# 测试部分\n",
    "from tensorflow.python.tools.inspect_checkpoint import print_tensors_in_checkpoint_file\n",
    "print_tensors_in_checkpoint_file(\"test-ckpt/model\",'weights,biases',None, True)\n",
    "\n",
    "with tf.name_scope('inputs'):\n",
    "    xs2 = tf.placeholder(tf.float32,[None,2],name='x_input')\n",
    "    ys2 = tf.placeholder(tf.float32,[None,1],name='y_input')\n",
    "with tf.name_scope('parameter'):\n",
    "    W1 = tf.Variable(tf.random_normal([2,8]),name='W1')\n",
    "    W2 = tf.Variable(tf.random_normal([8,1]),name='W2')\n",
    "    b1 = tf.Variable(tf.random_normal([1,8]),name='b1')\n",
    "    b2 = tf.Variable(tf.random_normal([1,1]),name='b2')\n",
    "\n",
    "# 把保存的变量提出来赋值给相应的变量\n",
    "saver = tf.train.Saver({\"layer1/weights/W\":W1, \"layer2/weights/W\":W2, \"layer1/biases/b\":b1, \"layer2/biases/b\":b2})\n",
    "\n",
    "a1 = tf.nn.relu(tf.matmul(xs2,W1)+b1)\n",
    "a2 = tf.matmul(a1,W2)+b2\n",
    "\n",
    "mse = tf.losses.mean_squared_error(a2,ys2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    saver.restore(sess, 'test-ckpt/model')\n",
    "    #print(sess.run(W1), sess.run(W2))\n",
    "    print(\"测试集均方误差：\",sess.run(mse, feed_dict={xs2: x_test, ys2: y_test}))\n",
    "    a2_value=sess.run(a2,feed_dict={xs2: x_test, ys2: y_test})\n",
    "    #a2_value_train=sess.run(a2,feed_dict={xs2: x_train, ys2: y_train})\n",
    "    #print(a2_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.35        18.9         94.18530427]\n",
      " [  0.27        43.          11.5818106 ]\n",
      " [  0.28        43.          13.16405284]\n",
      " [  0.33        33.4         24.54144933]\n",
      " [  0.3         50.          16.84330406]\n",
      " [  0.29        43.          14.74629449]\n",
      " [  0.3         43.          16.32853498]\n",
      " [  0.33        58.7         22.22981243]\n",
      " [  0.33        19.1         71.03018421]\n",
      " [  0.34        43.          22.65750277]\n",
      " [  0.31        43.          17.91077839]\n",
      " [  0.28        43.          13.16405284]\n",
      " [  0.33        65.3         22.71516604]\n",
      " [  0.27        41.          11.57933542]] \n",
      "\n",
      "[[  0.35        18.9         86.79      ]\n",
      " [  0.27        43.           8.35106383]\n",
      " [  0.28        43.          11.06382979]\n",
      " [  0.33        33.4         25.3       ]\n",
      " [  0.3         50.          15.39453125]\n",
      " [  0.29        43.          13.77659574]\n",
      " [  0.3         43.          14.375     ]\n",
      " [  0.33        58.7         25.8       ]\n",
      " [  0.33        19.1         64.15      ]\n",
      " [  0.34        43.          27.85904255]\n",
      " [  0.31        43.          19.60106383]\n",
      " [  0.28        43.          11.74202128]\n",
      " [  0.33        65.3         24.9       ]\n",
      " [  0.27        41.          20.33      ]] \n",
      "\n",
      "[[ 0.          0.         -0.08520917]\n",
      " [ 0.          0.         -0.38686649]\n",
      " [ 0.          0.         -0.18982785]\n",
      " [ 0.          0.          0.02998224]\n",
      " [ 0.          0.         -0.09410958]\n",
      " [ 0.          0.         -0.0703874 ]\n",
      " [ 0.          0.         -0.13589809]\n",
      " [ 0.          0.          0.13837936]\n",
      " [ 0.          0.         -0.10725151]\n",
      " [ 0.          0.          0.18670921]\n",
      " [ 0.          0.          0.08623437]\n",
      " [ 0.          0.         -0.1211062 ]\n",
      " [ 0.          0.          0.08774434]\n",
      " [ 0.          0.          0.43043112]] \n",
      "\n",
      "[ 0.          0.         -0.01651255]\n",
      "Using matplotlib backend: Qt5Agg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x29b5860c278>,\n",
       "  <matplotlib.axis.XTick at 0x29b5860c0b8>,\n",
       "  <matplotlib.axis.XTick at 0x29b5877a080>,\n",
       "  <matplotlib.axis.XTick at 0x29b58663518>,\n",
       "  <matplotlib.axis.XTick at 0x29b586639e8>,\n",
       "  <matplotlib.axis.XTick at 0x29b58663eb8>,\n",
       "  <matplotlib.axis.XTick at 0x29b5866b3c8>,\n",
       "  <matplotlib.axis.XTick at 0x29b5866b898>,\n",
       "  <matplotlib.axis.XTick at 0x29b5866bd68>,\n",
       "  <matplotlib.axis.XTick at 0x29b586722b0>,\n",
       "  <matplotlib.axis.XTick at 0x29b586727b8>,\n",
       "  <matplotlib.axis.XTick at 0x29b5866b978>,\n",
       "  <matplotlib.axis.XTick at 0x29b586634e0>,\n",
       "  <matplotlib.axis.XTick at 0x29b58672f98>,\n",
       "  <matplotlib.axis.XTick at 0x29b5867b2b0>],\n",
       " <a list of 15 Text xticklabel objects>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d=scarler.inverse_transform(np.append(x_test,a2_value,axis=1))\n",
    "print(d,'\\n')\n",
    "#a=npg_predicted_ori[:,0].reshape((14,1))\n",
    "#b=npg_predicted_ori[:,1].reshape((14,1))\n",
    "#c=npg_predicted_ori[:,2].reshape((14,1))\n",
    "#d=np.concatenate((a,b,c),axis=1)\n",
    "#print(d)\n",
    "e=scarler.inverse_transform(np.append(x_test,y_test,axis=1))\n",
    "print(e,'\\n')\n",
    "print((e-d)/e,'\\n')\n",
    "print(np.mean(((e-d)/e),axis=0))\n",
    "%matplotlib auto\n",
    "plt.plot(d[:,2])\n",
    "plt.plot(e[:,2])\n",
    "plt.xticks(np.arange(1,16,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure() # 用这个画图\n",
    "ax = fig.add_subplot(1,1,1) # 图片编号\n",
    "num=np.arange(1,20).reshape(y_train.shape)\n",
    "ax.scatter(num,y_train) # 点的编号\n",
    "lines = ax.plot(num,predition_value,'r-',lw=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib auto\n",
    "plt.plot(np.squeeze(costs))\n",
    "plt.ylabel('costs')\n",
    "plt.xlabel('epochs (per 5)')\n",
    "#plt.xticks(np.arange(0,5000,100))\n",
    "plt.title(\"Learning rate = \" + str(learning_rate))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
